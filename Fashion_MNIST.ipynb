{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgoSbqnKqo14"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "H7kaVoxcrEyH",
    "outputId": "5b32cbef-2893-420a-e0de-41f523b76363"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/fashion-mnist_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-OtLS82g65S"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ma3PGFN5rF4Z"
   },
   "outputs": [],
   "source": [
    "data=df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hS7jnKMcrN57"
   },
   "outputs": [],
   "source": [
    "x=data[:,1:]\n",
    "y=data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "v3G6SoMght5p",
    "outputId": "f7215926-07b3-4b7a-f1c9-d3a24507e03f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUZvJxj6rQ7c"
   },
   "outputs": [],
   "source": [
    "x_train=x.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvVLre_FrT9H"
   },
   "outputs": [],
   "source": [
    "x_train=x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hsjXYTJ7rXZC",
    "outputId": "54fce7e5-9802-417b-97b2-8593c1f6b6ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "WoVULGstrYoQ",
    "outputId": "3a3d0af2-be8e-4ad2-c38a-9f3d4f592600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fea36b50fd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea36b7b748>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEfqC0QCZQxK"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTuvdumOZQ4b"
   },
   "outputs": [],
   "source": [
    "y_train=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22yutnYgyH8K"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "gpt2AmqQyH4Z",
    "outputId": "80996509-d827-4707-b8c4-6dfdb75aab45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uxng-4JLyH0y",
    "outputId": "0422a338-948f-49fa-dffa-54391e0e10a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JaZn8Bj5ySGi"
   },
   "outputs": [],
   "source": [
    "df_test=df_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbOFWhv3ySB0"
   },
   "outputs": [],
   "source": [
    "x_test=df_test[:,1:]\n",
    "y_test=df_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsBc0VTIyR9S"
   },
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gi58S3r-yR5h"
   },
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsGjzHd8rjvP"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPool2D,Activation,BatchNormalization,Flatten,Dropout,MaxPooling2D\n",
    "from keras.optimizers import Adam,RMSprop,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRVMcp4brpcY"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2571
    },
    "colab_type": "code",
    "id": "1ZZ0NmENrtvt",
    "outputId": "42119143-daa8-4dc1-b70e-7a3e376e598b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/70\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.6113 - acc: 0.4260 - val_loss: 4.7421 - val_acc: 0.6989\n",
      "Epoch 2/70\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.9342 - acc: 0.6681 - val_loss: 4.2030 - val_acc: 0.7341\n",
      "Epoch 3/70\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.7903 - acc: 0.7185 - val_loss: 3.6431 - val_acc: 0.7686\n",
      "Epoch 4/70\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.7183 - acc: 0.7427 - val_loss: 3.4157 - val_acc: 0.7834\n",
      "Epoch 5/70\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.6776 - acc: 0.7554 - val_loss: 3.1289 - val_acc: 0.8022\n",
      "Epoch 6/70\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.6447 - acc: 0.7687 - val_loss: 3.0142 - val_acc: 0.8086\n",
      "Epoch 7/70\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.6227 - acc: 0.7782 - val_loss: 2.9470 - val_acc: 0.8126\n",
      "Epoch 8/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.6022 - acc: 0.7841 - val_loss: 2.7757 - val_acc: 0.8240\n",
      "Epoch 9/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5828 - acc: 0.7922 - val_loss: 2.6087 - val_acc: 0.8342\n",
      "Epoch 10/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5679 - acc: 0.7978 - val_loss: 2.4967 - val_acc: 0.8407\n",
      "Epoch 11/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5521 - acc: 0.8023 - val_loss: 2.4840 - val_acc: 0.8423\n",
      "Epoch 12/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5407 - acc: 0.8087 - val_loss: 2.2930 - val_acc: 0.8533\n",
      "Epoch 13/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5325 - acc: 0.8110 - val_loss: 2.3866 - val_acc: 0.8478\n",
      "Epoch 14/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5219 - acc: 0.8142 - val_loss: 2.3162 - val_acc: 0.8530\n",
      "Epoch 15/70\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.5087 - acc: 0.8197 - val_loss: 2.1542 - val_acc: 0.8619\n",
      "Epoch 16/70\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.5033 - acc: 0.8205 - val_loss: 2.1667 - val_acc: 0.8621\n",
      "Epoch 17/70\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4952 - acc: 0.8252 - val_loss: 2.0926 - val_acc: 0.8668\n",
      "Epoch 18/70\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4888 - acc: 0.8265 - val_loss: 2.1329 - val_acc: 0.8634\n",
      "Epoch 19/70\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4806 - acc: 0.8304 - val_loss: 2.0242 - val_acc: 0.8702\n",
      "Epoch 20/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4757 - acc: 0.8329 - val_loss: 2.0364 - val_acc: 0.8694\n",
      "Epoch 21/70\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4684 - acc: 0.8349 - val_loss: 1.9853 - val_acc: 0.8736\n",
      "Epoch 22/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4623 - acc: 0.8362 - val_loss: 2.0512 - val_acc: 0.8683\n",
      "Epoch 23/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4604 - acc: 0.8379 - val_loss: 2.0471 - val_acc: 0.8689\n",
      "Epoch 24/70\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.4518 - acc: 0.8393 - val_loss: 2.0200 - val_acc: 0.8717\n",
      "Epoch 25/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4493 - acc: 0.8416 - val_loss: 1.9522 - val_acc: 0.8752\n",
      "Epoch 26/70\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4459 - acc: 0.8431 - val_loss: 1.9107 - val_acc: 0.8779\n",
      "Epoch 27/70\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4403 - acc: 0.8421 - val_loss: 1.9911 - val_acc: 0.8727\n",
      "Epoch 28/70\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4357 - acc: 0.8462 - val_loss: 1.9529 - val_acc: 0.8750\n",
      "Epoch 29/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4315 - acc: 0.8480 - val_loss: 1.9098 - val_acc: 0.8782\n",
      "Epoch 30/70\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4270 - acc: 0.8492 - val_loss: 1.8931 - val_acc: 0.8784\n",
      "Epoch 31/70\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4245 - acc: 0.8497 - val_loss: 1.9329 - val_acc: 0.8764\n",
      "Epoch 32/70\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4201 - acc: 0.8511 - val_loss: 1.9155 - val_acc: 0.8774\n",
      "Epoch 33/70\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.4169 - acc: 0.8530 - val_loss: 1.8864 - val_acc: 0.8797\n",
      "Epoch 34/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.4153 - acc: 0.8539 - val_loss: 1.9210 - val_acc: 0.8774\n",
      "Epoch 35/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.4100 - acc: 0.8555 - val_loss: 1.8742 - val_acc: 0.8802\n",
      "Epoch 36/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.4053 - acc: 0.8568 - val_loss: 1.9186 - val_acc: 0.8782\n",
      "Epoch 37/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.4034 - acc: 0.8559 - val_loss: 1.8699 - val_acc: 0.8805\n",
      "Epoch 38/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.4035 - acc: 0.8568 - val_loss: 1.9633 - val_acc: 0.8738\n",
      "Epoch 39/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3991 - acc: 0.8597 - val_loss: 1.8243 - val_acc: 0.8830\n",
      "Epoch 40/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3993 - acc: 0.8589 - val_loss: 1.8957 - val_acc: 0.8790\n",
      "Epoch 41/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3953 - acc: 0.8606 - val_loss: 1.9423 - val_acc: 0.8751\n",
      "Epoch 42/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3918 - acc: 0.8603 - val_loss: 1.8908 - val_acc: 0.8784\n",
      "Epoch 43/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3878 - acc: 0.8622 - val_loss: 1.8343 - val_acc: 0.8826\n",
      "Epoch 44/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3873 - acc: 0.8637 - val_loss: 1.8998 - val_acc: 0.8778\n",
      "Epoch 45/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3823 - acc: 0.8643 - val_loss: 1.8584 - val_acc: 0.8807\n",
      "Epoch 46/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3827 - acc: 0.8640 - val_loss: 1.9038 - val_acc: 0.8774\n",
      "Epoch 47/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3791 - acc: 0.8660 - val_loss: 1.9475 - val_acc: 0.8753\n",
      "Epoch 48/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3783 - acc: 0.8669 - val_loss: 1.8341 - val_acc: 0.8831\n",
      "Epoch 49/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3762 - acc: 0.8664 - val_loss: 1.8986 - val_acc: 0.8782\n",
      "Epoch 50/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3738 - acc: 0.8688 - val_loss: 1.8791 - val_acc: 0.8784\n",
      "Epoch 51/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3734 - acc: 0.8689 - val_loss: 1.9178 - val_acc: 0.8762\n",
      "Epoch 52/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3697 - acc: 0.8697 - val_loss: 1.8917 - val_acc: 0.8772\n",
      "Epoch 53/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3699 - acc: 0.8697 - val_loss: 1.9289 - val_acc: 0.8766\n",
      "Epoch 54/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3652 - acc: 0.8718 - val_loss: 1.8887 - val_acc: 0.8781\n",
      "Epoch 55/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3666 - acc: 0.8701 - val_loss: 1.9424 - val_acc: 0.8756\n",
      "Epoch 56/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3618 - acc: 0.8726 - val_loss: 1.9524 - val_acc: 0.8751\n",
      "Epoch 57/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3595 - acc: 0.8731 - val_loss: 2.0233 - val_acc: 0.8710\n",
      "Epoch 58/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3587 - acc: 0.8724 - val_loss: 1.9861 - val_acc: 0.8727\n",
      "Epoch 59/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3579 - acc: 0.8727 - val_loss: 2.0016 - val_acc: 0.8715\n",
      "Epoch 60/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3573 - acc: 0.8742 - val_loss: 1.9690 - val_acc: 0.8732\n",
      "Epoch 61/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3532 - acc: 0.8742 - val_loss: 1.9131 - val_acc: 0.8776\n",
      "Epoch 62/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3537 - acc: 0.8746 - val_loss: 1.9720 - val_acc: 0.8722\n",
      "Epoch 63/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3524 - acc: 0.8744 - val_loss: 1.9302 - val_acc: 0.8751\n",
      "Epoch 64/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3445 - acc: 0.8782 - val_loss: 1.9252 - val_acc: 0.8759\n",
      "Epoch 65/70\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3473 - acc: 0.8762 - val_loss: 1.9762 - val_acc: 0.8733\n",
      "Epoch 66/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3485 - acc: 0.8758 - val_loss: 1.9948 - val_acc: 0.8714\n",
      "Epoch 67/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3453 - acc: 0.8756 - val_loss: 1.9908 - val_acc: 0.8721\n",
      "Epoch 68/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3443 - acc: 0.8765 - val_loss: 2.0536 - val_acc: 0.8682\n",
      "Epoch 69/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3416 - acc: 0.8781 - val_loss: 2.0357 - val_acc: 0.8688\n",
      "Epoch 70/70\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3415 - acc: 0.8791 - val_loss: 2.0309 - val_acc: 0.8691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea386497f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=70,batch_size=512,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "T0NH52Wcwh-O",
    "outputId": "860dba41-3848-4a1c-80ad-34dc56889b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 120us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0308554361768802, 0.8691]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxG9PlU7ZzJS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fashion_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
